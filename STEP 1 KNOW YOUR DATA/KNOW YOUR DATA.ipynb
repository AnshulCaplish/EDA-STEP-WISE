{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore our DF  (Shape, head, tail, dtypes, info, describe, count, nunique, columns, isnull, value_counts, rename, duplicated, drop_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-47237ac57e0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# if we do this df.shape() we get error --> TypeError: 'tuple' object is not callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# shape --> Tells rows * columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Row , Column \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# Index 0= no. of rows and index=1 = no. of columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# shape is just an attribute, not a method. Just use df.shape (no parenthesis).\n",
    "# (The error message is not telling us that df is a tuple, it is telling you that df.shape is a tuple.)\n",
    "# if we do this df.shape() we get error --> TypeError: 'tuple' object is not callable\n",
    "# shape --> Tells rows * columns\n",
    "print(\"Row , Column \",df.shape)\n",
    "# Index 0= no. of rows and index=1 = no. of columns\n",
    "print()\n",
    "print(\"No of ROWs \",df.shape[0])\n",
    "print()\n",
    "print(\"NO of columns:\" ,df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) HEAD, TAIL,VALUES, NSMALLEST, NLARGEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tells first 5 rows.\n",
    "print(df.head(5))\n",
    "\n",
    "# tells last 5 rows\n",
    "print(df.tail(5))\n",
    "\n",
    "# It gives the rows as a numpy array\n",
    "# To get the actual data inside a data structure, one need only access the values property\n",
    "print(df.values)\n",
    "# <class 'numpy.ndarray'>\n",
    "\n",
    "\n",
    "\n",
    "# return the smallest or largest n values. \n",
    "print(df.nsmallest(3, 'ReleaseNumber'))\n",
    "print(df.nsmallest(3,[ 'ReleaseNumber','SKU_number']))\n",
    "print(df.nlargest(5, ['SKU_number']))\n",
    "print(df.nlargest(3,[ 'ReleaseNumber','SKU_number']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) DTYPES, VALUE_COUNTS, select_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Each Column Dattype\n",
    "# int 64 means discrete data\n",
    "# float 64 means continous data\n",
    "# object means categorical data here( SoldFlag and New_Realease_Flag is also categorical data \n",
    "# becos they have only two values either 0/1 which can be treat as yes/no)\n",
    "# categorical values does not need to be character type it can be any data that has very limited values or fix no of values.\n",
    "# dtypes tell the \n",
    "print(df.dtypes)\n",
    "\n",
    "# will return the number of columns of each type in a DataFrame:\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# select numeric columns BY DTYPES\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "numeric_cols = df_numeric.columns.values\n",
    "print(\"--------numeric_cols-------------\")\n",
    "print(numeric_cols)\n",
    "\n",
    "# select non numeric columns\n",
    "df_categorical = df.select_dtypes(exclude=[np.number])\n",
    "categorical_cols = df_categorical.columns.values\n",
    "print(\"--------categorical_cols----------\")\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) INFO, COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info tells the information about the values of the data\n",
    "print(df.info())\n",
    "\n",
    "# it tells the memory usage by the columns.\n",
    "df.info(memeory_usage='deep')\n",
    "\n",
    "# it wil give the individual column  memory details.\n",
    "df.memory_usage(deep=True)\n",
    "\n",
    "# gives the list of column name\n",
    "print(df.columns)\n",
    "\n",
    "# It tells the index\n",
    "print(\"\\n \",df.index)\n",
    "# start  is first row index\n",
    "# stop is last row index\n",
    "# o/p --> RangeIndex(start=0, stop=198924, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It counts the total no of rows of all the columns whether duplicate or not but doesnot include null.. \n",
    "print(df.count())\n",
    "# We can count the no of rows for  a particular column put on a condition with .count()\n",
    "print()\n",
    "print(df[df['PriceReg']>2000].count())\n",
    "# counting rows that matches the given condition.\n",
    "print()\n",
    "print(df[df['File_Type']=='Historical'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) UNIQUE & NUNIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the count of unique values in the data use nunique, no duplicates and no null.\n",
    "print(df.nunique())\n",
    "\n",
    "# Let's learn a new function called unique\n",
    "# It tells the name of the unique values in the Column Specified and doesnot show duplicate as well as not show null values.\n",
    "print()\n",
    "print(df['MarketingType'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) DESCRIBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it tells the summary of the statistica data and shows only numerical values not categorical.\n",
    "# count non null values\n",
    "print(df.describe())\n",
    "\n",
    "#  for categorical values put include = object\n",
    "# count = total non null values\n",
    "# top= most occuring value\n",
    "# freq= count of top value\n",
    "print(df.describe(include='object'))\n",
    "\n",
    "# all = to get all values describe numerical as well as categorical\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# To see details of a particular column\n",
    "print(df['Order'].describe())\n",
    "print(\"-------------- describe Transpose--------------\")\n",
    "print(df.describe().transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) DUPLICATED, SUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicated\n",
    "# To count the duplicate rows\n",
    "# It shows the boolean result false for non duplicates and true for duplicate values.\n",
    "print(df.duplicated)\n",
    "# When ever we have boolean result we can easily count the true values using sum()\n",
    "# To count the duplicated rows\n",
    "# data.duplicated().sum()\n",
    "print(df.duplicated().sum())\n",
    "print(df[df.duplicated()])\n",
    "## this function is used to show only duplicate row \n",
    "## they give the second duplicated value with compare with first\n",
    "## if want to see this put the above 3 shell \n",
    "df.duplicated(keep='first')\n",
    "df.duplicated(keep='last') ## they give the first duplicated value with compare with second \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) DROP_DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # It drops duplicate values, by default it keeps first value.\n",
    "df.drop_duplicates() \n",
    "# Drop Duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# we can drop duplicates even with the particular column name. \n",
    "# All duplicate of those column will drop the correnponding rows data also.\n",
    "df.drop_duplicates(['k1'])\n",
    "\n",
    "# If we want to keep last duplicate values then we put parameter keep='last'\n",
    "df.drop_duplicates(['k1', 'k2'], keep='last',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11) ISNULL(), NOTNULL(),ANY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null Values\n",
    "print(df.isnull())\n",
    "print(df.isnull().sum())\n",
    "print(df.notnull().sum())\n",
    "print(df['SoldFlag'].isnull())\n",
    "\n",
    "# It tells which row has null\n",
    "print(df[df['SoldFlag'].isnull()])\n",
    "\n",
    "# Totalcount of null values\n",
    "print(df['SoldFlag'].isnull().sum())\n",
    "\n",
    "# Null Values\n",
    "print()\n",
    "\n",
    "# If we have to see rows with null when we dont know column name. It will show all the  rows that have any null in it. \n",
    "print(df[df.isnull().any(axis=1)])\n",
    "\n",
    "# To see non null values count\n",
    "print(df[df['SoldFlag'].notnull()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12) value_counts(), set_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counnts is applied only in columns not in df\n",
    "# Value_counts tells the frequency of unique values individually does not include null.\n",
    "print(df['File_Type'].value_counts())\n",
    "print()\n",
    "print(df['StrengthFactor'].value_counts())\n",
    "print()\n",
    "\n",
    "# it will give the value count in percentages.\n",
    "print(df['SoldFlag'].value_counts(normalize=True))\n",
    "\n",
    "# Create index\n",
    "#print(df1.set_index('States'))\n",
    "\n",
    "# to plot barplot with value_counts\n",
    "%inline matplotlib\n",
    "df.StrengthFactor.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13) RENAME, add_prefix, add_Suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to rename any column name\n",
    "df.rename(columns={'SKU_number':'Product_ID'}, inplace=True)\n",
    "df.rename(columns={'SKU_number':'Product_ID','File_Type':'Product_Type'}, inplace=True)\n",
    "print(df.columns)\n",
    "\n",
    "or\n",
    "df_cols=['Product_ID','Product_Type','country']\n",
    "df.columns=df_cols\n",
    "\n",
    "# It will add the prefix to the column name of the dataframe\n",
    "df.add_prefix('X_')\n",
    "\n",
    "# It will add the suffix to the column name of the dataframe\n",
    "df.add_Suffix('_X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14) options.display.max_columns, set_option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tells the limit of columns that can be displayed in output in jupyter notebook at a time.\n",
    "pd.options.display.max_columns\n",
    "# tells the limit of rows that can be displayed in output in jupyter notebook at a time.\n",
    "pd.options.display.max_rows\n",
    "# to change the limit of output of rows.\n",
    "pd.set_option('display.max_rows',70)\n",
    "pd.options.display.max_rows\n",
    "# to change the limit of column in output\n",
    "pd.set_option('display.max_columns',30)\n",
    "pd.options.display.max_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15) FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) filtering columns 1961, 2000, and 2015\n",
    "dataset.filter(items=[\"1961\", \"2000\", \"2015\"]).head()\n",
    "\n",
    "# (2) filtering for years 2000 and later\n",
    "dataset.filter(regex=\"^2\", axis=1).head()\n",
    "\n",
    "# (3) filtering countries that start with A\n",
    "dataset.filter(regex=\"^A\", axis=0).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
